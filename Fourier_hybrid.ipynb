{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "from pyinn import conv2d_depthwise as conv2\n",
    "from pyinn.modules import Conv2dDepthwise as Conv2dD\n",
    "# import Transforms\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"../Prototype_Network_Training/mIN_train.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)\n",
    "a = 256\n",
    "b = 42\n",
    "newdata = torch.stack([torch.ByteTensor(data[0][i]).float().view(84,84,3).transpose(0,2).contiguous() \n",
    "                       for i in range(64)],0)\n",
    "newdata = Variable(newdata).cuda()\n",
    "criterion = nn.MSELoss()\n",
    "targ = Variable(torch.randn(64,b,b,a)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gpytorch.utils.fft import fftc,ifftc\n",
    "from torch.autograd import Variable, Function\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class FFT1(Function):\n",
    "    def __init__(self):\n",
    "        super(FFT1, self).__init__()\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        return fftc(inp)\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        return ifftc(grad)\n",
    "    \n",
    "class iFFT1(Function):\n",
    "    def __init__(self):\n",
    "        super(iFFT1, self).__init__()\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return ifftc(inp)\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        return fftc(grad)\n",
    "    \n",
    "class Conv3dF(nn.Module):\n",
    "    def __init__(self,nchannels):\n",
    "        super(Conv3dF,self).__init__()\n",
    "        self.nchannels = nchannels//2+1\n",
    "        self.striper = Variable(torch.ones(1,nchannels,1,1), requires_grad=False).cuda()\n",
    "                        #Conv2dD(channels = nchannels, kernel_size=3, padding=1)\n",
    "#         self.mul = Parameter(torch.randn(1,nchannels,1,1))\n",
    "        self.fft = FFT1()\n",
    "        self.ifft = iFFT1()\n",
    "        self.wre = Parameter(torch.randn(nchannels//2+1,1,3,3))\n",
    "        self.wim = Parameter(torch.randn(nchannels//2+1,1,3,3))\n",
    "#         self.convre = Conv2dD(channels = nchannels//2+1, kernel_size=3, padding=1)\n",
    "#         self.convim = Conv2dD(channels = nchannels//2+1, kernel_size=3, padding=1)\n",
    "                                                # TODO proper weight initialization\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        fi = self.fft(self.striper*inp)\n",
    "        result = Variable(torch.zeros(*fi.size()), requires_grad=True).cuda()\n",
    "        result[:,:,:,:,0].add(conv2(fi[:,:,:,:,0], self.wre, padding=1))\n",
    "        result[:,:,:,:,0].sub(conv2(fi[:,:,:,:,1], self.wim, padding=1))\n",
    "        result[:,:,:,:,1].add(conv2(fi[:,:,:,:,0], self.wim, padding=1))\n",
    "        result[:,:,:,:,1].add(conv2(fi[:,:,:,:,1], self.wre, padding=1))\n",
    "#         result.add(self.bias)\n",
    "        \n",
    "#         re = self.convre(fi[:,:,:,:,0])-self.convim(fi[:,:,:,:,1])\n",
    "#         im = self.convim(fi[:,:,:,:,0])+self.convre(fi[:,:,:,:,1])\n",
    "        \n",
    "#         result = torch.cat([im.unsqueeze(4),\n",
    "#                             re.unsqueeze(4)],\n",
    "#                            dim=4)\n",
    "\n",
    "#         k = fw[:,:,:,:,0]*fi.sum(4)\n",
    "#         d = fi[:,:,:,:,1]*fw.sum(4)\n",
    "#         c = fi[:,:,:,:,0]*(fw[:,:,:,:,0]-fw[:,:,:,:,1])\n",
    "#         result = torch.cat([(k-d).unsqueeze(4),\n",
    "#                             (k-c).unsqueeze(4)],dim=4)\n",
    "\n",
    "        return self.ifft(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14956  parameters in Fourier neural net.\n"
     ]
    }
   ],
   "source": [
    "class testnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(testnet, self).__init__()\n",
    "        self.process = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(3,a,(1,1),padding=0),\n",
    "            nn.ReLU(),\n",
    "            Conv3dF(a),\n",
    "            nn.ReLU(),\n",
    "            Conv3dF(a),\n",
    "            nn.ReLU(),\n",
    "            Conv3dF(a),\n",
    "            nn.ReLU(),\n",
    "            Conv3dF(a),\n",
    "            nn.ReLU(),\n",
    "            Conv3dF(a),\n",
    "            nn.ReLU(),\n",
    "            Conv3dF(a),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return self.process(inp)\n",
    "\n",
    "net = testnet().cuda()\n",
    "nweights = sum([i.numel() for i in list(net.parameters())])\n",
    "print(nweights,\" parameters in Fourier neural net.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.32883977890015\n"
     ]
    }
   ],
   "source": [
    "# FOURIER 3D\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    net.zero_grad()\n",
    "    out = net(newdata)\n",
    "    loss = criterion(out,targ)\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#               84\n",
    "# 1973 Mb  64       30.15\n",
    "# 3401 Mb  128      59.38\n",
    "# 6271 Mb  256      114.55\n",
    "# DEAD     512\n",
    "#               42\n",
    "# 1067 Mb   64      8.69\n",
    "# 1579 Mb  128      24.09\n",
    "# 2641 Mb  256      50.69\n",
    "# 4737 Mb  512      60.91   (!)\n",
    "# 8913 Mb  1024     148.68  (???)\n",
    "#               16\n",
    "# 833 Mb   256 16   6.10\n",
    "# 1137 Mb  512 16   11.42   (!)\n",
    "# 1745 Mb  1024 16  27.67   (!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
